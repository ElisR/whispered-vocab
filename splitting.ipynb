{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating audio\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub.utils import mediainfo\n",
    "\n",
    "from pydub.playback import play\n",
    "\n",
    "# Modifying strings\n",
    "import re\n",
    "\n",
    "# Machine Learning Model\n",
    "import torch\n",
    "import whisper\n",
    "\n",
    "# Saving output\n",
    "import pandas as pd\n",
    "\n",
    "# Checking confidence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose File\n",
    "filename_dir = \"french_audio/split_testing/\"\n",
    "filename = \"01.2 Nationality, Language, Country.mp3\"\n",
    "\n",
    "filename_prefix = filename[:4]\n",
    "filename_title = filename[5:-4]\n",
    "\n",
    "track = AudioSegment.from_mp3(filename_dir + filename)\n",
    "original_bitrate = mediainfo(filename_dir + filename)[\"bit_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters empirically tuned\n",
    "chunks = split_on_silence(track, min_silence_len=600, silence_thresh=-30, keep_silence=200)\n",
    "\n",
    "def chunk_filename(filename_prefix, i):\n",
    "    return filename_prefix + \"_\" + str(i) + \".mp3\"\n",
    "\n",
    "# Save split up audio\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.export(chunk_filename(filename_prefix, i).format(i), format=\"mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Apply to Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 5.76 GiB total capacity; 4.02 GiB already allocated; 38.69 MiB free; 4.03 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-4eb2e3b00514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"medium\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/whisper/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    983\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    984\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 5.76 GiB total capacity; 4.02 GiB already allocated; 38.69 MiB free; 4.03 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"medium\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c127b2b504c1499d8d7a8adba60b4a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phrases_fr = []\n",
    "phrases_en = []\n",
    "\n",
    "logprobs_fr = []\n",
    "logprobs_en = []\n",
    "\n",
    "# Has to be changed if on CPU vs GPU\n",
    "decode_options = {\"fp16\": True}\n",
    "\n",
    "num_chunks = len(chunks)\n",
    "for i in tqdm(range(num_chunks)):\n",
    "    # Ignoring the English title\n",
    "    if i > 1:\n",
    "        result_fr = model.transcribe(chunk_filename(filename_prefix, i), language=\"fr\", task=\"transcribe\", **decode_options)\n",
    "        result_en = model.transcribe(chunk_filename(filename_prefix, i), language=\"fr\", task=\"translate\", **decode_options)\n",
    "\n",
    "        # Saving text\n",
    "        phrases_fr.append(result_fr[\"text\"])\n",
    "        phrases_en.append(result_en[\"text\"])\n",
    "\n",
    "        # Saving confidence\n",
    "        logprobs_fr.append(result_fr[\"segments\"][0][\"avg_logprob\"])\n",
    "        logprobs_en.append(result_en[\"segments\"][0][\"avg_logprob\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Un passeport.', \" Les papiers d'identité.\", \" une carte d'identité.\", ' un continent.', ' un pays.', ' une nation.', ' La nationalité.', ' Fatima va demander la nationalité française.', \" être d'origine.\", \" C'est un français d'origine italienne.\", ' étranger', ' étrangère', ' Un étranger.', ' Une étrangère.', ' Immigré.', ' un immigré.', ' Une immigrée.', \" Les immigrés ont parfois du mal à s'intégrer.\", \" l'immigration\", ' émigré.', ' Une langue.', ' La langue maternelle.', ' Une langue étrangère.', ' BILANG', ' Le rebs', \" L'Afrique.\", \" L'Amérique.\", ' Lasi.', \" l'Australie.\", ' La France.', ' Français, Française.', \" l'Allemagne.\", ' allemand allemande', ' La Grande Bretagne', ' Britannique.', \" L'Angleterre\", ' Anglais, Anglaise.', \" L'Italie.\", ' Italien, Italienne.', \" l'Espagne.\", ' Espagnol, Espagnol', ' le Portugal.', ' Portugais, Portugaises.', ' La Belgique.', ' Belge.', ' Les Pays-Bas.', ' néerlandais, néerlandaises.', ' La Hollande.', ' Hollandaise', ' Le Luxembourg', ' Luxembourgeois, Luxembourgeoise.', \" L'Autriche\", ' Autrichien, Autrichienne.', ' La Grèce.', ' grec', ' grec.', \" l'Irlande.\", ' Irlandais, Irlandaises.', ' La Finlande.', ' Finlandais, Finlandaises.', ' La Suède.', ' Suédois, suédoise.', ' La Norvège', ' norvégien, norvégienne.', ' Le Danemark.', ' Danois, Danois.', ' Scandinave.', ' La Suisse', ' Suisse', ' Un une Suisse', ' une Suisse.', ' La Russie.', ' Russe.', ' La Pologne.', ' Poulonnais, Poulonnaise.', ' La République check.', ' Chick.', ' La Slovakie.', ' Slovak.', ' La Turquie', ' TURKE', ' TUR', \" l'Albanie\", ' Albanais, Albanais.', ' La Bulgarie', ' BULGAR', ' La Roumanie', ' Roumain, Roumaine.', ' La Hongrie.', ' On groie, on groise.', \" l'estonie\", ' Estonia estonienne', ' La Létonie.', ' Litton, Litton.', ' La Lituanie.', \" L'Ithuania, L'Ithuanienne.\", ' La biaislorusie.', ' Biélorus.', \" L'Ukraine.\", ' Ukraine, ukrainienne', ' La Croatie.', ' court', ' La Serbe.', ' SEM.', ' La Slovenie.', ' Sloven.', ' La Bosnie-Herzegovine', ' BUSNIAGUE', ' Les États-Unis.', ' Les USA.', ' américain, américaine.', ' Le Canada.', ' Canadiens, Canadiennes.', ' le Mexique.', ' Mexica, Mexican', ' Le Brésil', ' Brésilien, Brésilienne.', ' La Chine', ' Chinois, Chinois', ' Le Japon.', ' japonais, japonaises', \" l'Inde.\", ' India, Indienne.', \" l'Algérie\", ' Algérien, Algérienne.', ' Le marotte.', ' Marocain, Marocaine.', ' La Tunisie.', ' Tunisien, Tunisienne.', ' Le Maghreb.', ' Magribin, Magribin.', \" l'Egypte.\", ' Égyptien, Égyptienne.']\n"
     ]
    }
   ],
   "source": [
    "print(phrases_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Le rebs'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_fr[np.argmin(logprobs_fr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('un passeport', 'a passport!'), (\"les papiers d'identité\", 'identity papers'), (\"une carte d'identité\", 'a identity card'), ('un continent', 'a continent'), ('un pays', 'a country!'), ('une nation', 'a nation'), ('la nationalité', 'Nationality'), ('fatima va demander la nationalité française', 'fatima will ask the French nationality'), (\"être d'origine\", 'to be of origin'), (\"c'est un français d'origine italienne\", \"it's a French from Italian origin\"), ('étranger', 'Stranger'), ('étrangère', 'Stranger'), ('un étranger', 'a stranger'), ('une étrangère', 'a stranger'), ('Immigré', 'Immigrate!'), ('un immigré', 'an immigrant'), ('une immigrée', 'a immigrant'), (\"les immigrés ont parfois du mal à s'intégrer\", 'immigrants sometimes have trouble integrating themselves'), (\"l'immigration\", 'Immigration'), ('émigré', 'Emigré'), ('une langue', 'a language'), ('la langue maternelle', 'the mother tongue'), ('une langue étrangère', 'a foreign language'), ('bilang', 'bye now!'), ('le contre premier… Le H whether mount Le g automobile Le Hype Le vin Le vin Le soap Le vin Le roue Le vin', '息'), (\"L'Afrique\", 'Africa'), (\"L'Amérique\", 'the Mary'), ('Lasi', 'Lazy!'), (\"l'Australie\", 'Australia'), ('La France', 'France'), ('Français, Française', 'French, French'), (\"l'Allemagne\", 'Germany'), ('allemand allemande', 'German, German'), ('La Grande Bretagne', 'Great Britain'), ('Britannique', 'Britain'), (\"L'Angleterre\", 'England'), ('Anglais, Anglaise', 'English, English'), (\"L'Italie\", 'Italy'), ('Italien, Italienne', 'Italian, Italian'), (\"l'Espagne\", 'Spain'), ('Espagnol, Espagnol', 'Spanish, Spanish'), ('le Portugal', 'Portugal'), ('Portugais, Portugaises', 'Portuguese, Portuguese'), ('La Belgique', 'Belgium'), ('Belge', 'Belge'), ('Les Pays-Bas', 'the countries'), ('néerlandais, néerlandaises', 'ny-en-lande, Ny-en-landese'), ('La Hollande', 'the Netherlands'), ('Hollandaise', 'Dutch, Dutch'), ('Le Luxembourg', 'Luxembourg'), ('Luxembourgeois, Luxembourgeoise', 'Luxembourgian, Luxembourgian'), (\"L'Autriche\", 'Austria'), ('Autrichien, Autrichienne', 'Autrichian, Autrichian'), ('La Grèce', 'the Greece'), ('grec', 'Greek'), ('grec', 'Greek'), (\"l'Irlande\", 'Ireland'), ('Irlandais, Irlandaises', 'Irish, Irish'), ('La Finlande', 'the Finland'), ('Finlandais, Finlandaises', 'Finland, Finland'), ('La Suède', 'Sweden'), ('suédois, suédoise', 'Swedish, Swedish'), ('La Norvège', 'Norway'), ('norvégien, norvégienne', 'Norwegian, Norwegian'), ('Le Danemark', 'Denmark'), ('Danois, Danois', 'Danua, Danuaz'), ('Scandinave', 'Scandinavian'), ('La Suisse', 'Switzerland'), ('Suisse', 'Switzerland'), ('un une Suisse', 'A Swiss'), ('une Suisse', 'A Swiss'), ('La Russie', 'Russia'), ('Russe', 'Russia'), ('La Pologne', 'Poland'), ('Poulonnais, Poulonnaise', 'Polonaise, Polonaise'), ('la République check', 'the Czech Republic'), ('Chick', 'Check'), ('La Slovakie', 'the Slovakian language'), ('Slovak', 'depending on the possible找, the question can be asked, but I have to use'), ('La Turquie', 'Turkey'), ('turke', 'Turkey'), ('tur', 'Turkey'), (\"l'Albanie\", 'Albania'), ('Albanais, Albanais', 'Albanian, Albanese'), ('La Bulgarie', 'Bulgaria'), ('bulgar', 'bulgar'), ('La Roumanie', 'Romania'), ('Roumain, Roumaine', 'Roman, Romanian'), ('La Hongrie', 'Hungary'), ('on groie, on groise', 'Hungrois, Hungroise'), (\"l'estonie\", 'Estonia'), ('estonia estonienne', 'Estonia, Estonian'), ('La Létonie', 'Lettony'), ('Litton, Litton', 'Litton, Litton'), ('La Lituanie', 'Lituan'), (\"L'Ithuania, L'Ithuanienne\", 'Lithuania, Lithuanian'), ('la biaislorusie', 'the Belarusian'), ('Biélorus', 'Belarus'), (\"L'Ukraine\", 'Ukraine'), ('ukraine, ukrainienne', 'Ukrainian, Ukrainian'), ('La Croatie', 'the Croatia'), ('court', 'fit'), ('La Serbe', 'the Serb'), ('sem', 'sem'), ('La Slovenie', 'Slovenia'), ('Sloven', 'Sloven'), ('La Bosnie-Herzegovine', 'Bosnia Herzegovina'), ('busniague', 'be snow'), ('Les États-Unis', 'the United States'), ('les USA', 'usa'), ('américain, américaine', 'American, American'), ('Le Canada', 'Canada'), ('Canadiens, Canadiennes', 'Canadian, Canadian'), ('le Mexique', 'the Mexique'), ('Mexica, Mexican', 'Mexican, Mexican'), ('Le Brésil', 'Brazil'), ('Brésilien, Brésilienne', 'Brazilian, Brazilian'), ('La Chine', 'China'), ('Chinois, Chinois', 'Chinese, Chinese'), ('Le Japon', 'Japan'), ('japonais, japonaises', 'Japanese, Japanese'), (\"l'Inde\", 'Linde'), ('India, Indienne', 'India, Indian'), (\"l'Algérie\", 'Algeria'), ('Algérien, Algérienne', 'Algerian, Algerian'), ('le marotte', 'the lamb'), ('Marocain, Marocaine', 'Moroccan, Moroccan'), ('La Tunisie', 'Tunisia'), ('Tunisien, Tunisienne', 'Tunisian Tunisian'), ('Le Maghreb', 'the Maghreb'), ('Magribin, Magribin', 'Magribin, Magribin'), (\"l'Egypte\", 'Egypt'), ('Égyptien, Égyptienne', 'Egyptian, Egyptian')]\n"
     ]
    }
   ],
   "source": [
    "def sanitise(phrase):\n",
    "    # Strip whitespace then full stop\n",
    "    stripped = phrase.strip().strip(\".\")\n",
    "\n",
    "    phrase_clean = None\n",
    "    # Un-capitalize phrases\n",
    "    # All uppers are usually errors\n",
    "    if stripped.isupper():\n",
    "        phrase_clean = stripped.lower()\n",
    "    # Title case is sometimes a noun, also check for empty string\n",
    "    elif (stripped.split(\" \", 1)[0] == \"The\" or not stripped.istitle()) and len(stripped) > 1:\n",
    "        phrase_clean = stripped[0].lower() + stripped[1:]\n",
    "    else:\n",
    "        phrase_clean = stripped\n",
    "\n",
    "    return phrase_clean\n",
    "\n",
    "# Sanitise all outputs\n",
    "pairs = [ tuple(map(sanitise, phrase_pair)) for phrase_pair in zip(phrases_fr, phrases_en)]\n",
    "\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foolishly unzipping previously unzipped quantity\n",
    "# Putting it in a data frame\n",
    "data = pd.DataFrame(dict(zip([\"phrases_fr\", \"phrases_en\"], zip(*pairs))))\n",
    "\n",
    "# Saving to CSV\n",
    "CSV_title = re.sub(\",? \", \"_\", filename_title)\n",
    "data.to_csv(CSV_title + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
