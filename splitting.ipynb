{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding audio files\n",
    "import glob\n",
    "\n",
    "# Manipulating audio\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub.utils import mediainfo\n",
    "\n",
    "# Testing audio\n",
    "from pydub.playback import play\n",
    "\n",
    "# Generating Anki deck\n",
    "import genanki\n",
    "import random\n",
    "\n",
    "# Resetting random seed\n",
    "from datetime import datetime\n",
    "\n",
    "# Modifying strings\n",
    "import re\n",
    "\n",
    "# Machine Learning Model\n",
    "import torch\n",
    "import whisper\n",
    "\n",
    "# Saving output\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "# Checking confidence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#DEVICE = \"cpu\"\n",
    "\n",
    "# Has to be changed if on CPU vs GPU\n",
    "fp16_true = not (DEVICE == \"cpu\")\n",
    "decode_options = {\"fp16\": fp16_true}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful to only run this cell once because it eats up VRAM\n",
    "model = whisper.load_model(\"medium\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting for each phrase\n",
    "def sanitise(phrase):\n",
    "    \"\"\"Sanitise a phrase, which for our purposes means:\n",
    "    - Remove leading and trailing whitespace\n",
    "\n",
    "    Args:\n",
    "        phrase (str): Phrase to sanitise.\n",
    "\n",
    "    Returns:\n",
    "        str: Sanitised phrase.\n",
    "    \"\"\"\n",
    "\n",
    "    # Strip whitespace then full stop\n",
    "    stripped = phrase.strip().strip(\".\")\n",
    "\n",
    "    # Often preceding proper nouns\n",
    "    exceptions = [\"The\", \"La\", \"Le\", \"L\", \"Les\"]\n",
    "\n",
    "    phrase_clean = None\n",
    "    # Un-capitalize phrases\n",
    "    # All uppers are usually errors\n",
    "    if stripped.isupper():\n",
    "        phrase_clean = stripped.lower()\n",
    "    # Title case is sometimes a noun, also check for empty string\n",
    "    # Also check it's not a question\n",
    "    elif (re.split(\" |'\", stripped)[0] in exceptions or not stripped.istitle()) and len(stripped) > 1 and not stripped[-1] == \"?\":\n",
    "        phrase_clean = stripped[0].lower() + stripped[1:]\n",
    "    else:\n",
    "        phrase_clean = stripped\n",
    "\n",
    "    return phrase_clean\n",
    "\n",
    "# This is the function that wraps all the difficult parts\n",
    "def generate_phrases(chunk_filename_list, decode_options):\n",
    "    \"\"\"Generate phrases from a list of audio files.\n",
    "    \n",
    "    Args:\n",
    "        chunk_filename_list (list): List of filenames of audio files.\n",
    "        decode_options (dict): Dictionary of options for decoding.\n",
    "        \n",
    "    Returns:\n",
    "        phrases_fr (list): List of French phrases.\n",
    "        phrases_en (list): List of English translations.\n",
    "    \"\"\"\n",
    "\n",
    "    phrases_fr = []\n",
    "    phrases_en = []\n",
    "\n",
    "    for chunk_filename in tqdm(chunk_filename_list):\n",
    "        # Transcribe using loaded model\n",
    "        result_fr = model.transcribe(chunk_filename, language=\"fr\", task=\"transcribe\", **decode_options)\n",
    "        result_en = model.transcribe(chunk_filename, language=\"fr\", task=\"translate\", **decode_options)\n",
    "\n",
    "        # Saving text\n",
    "        phrases_fr.append(result_fr[\"text\"])\n",
    "        phrases_en.append(result_en[\"text\"])\n",
    "\n",
    "    return phrases_fr, phrases_en\n",
    "\n",
    "# Return numbers \"xx.y\" and section name\n",
    "def split_filename(filename):\n",
    "    # TODO Fix to be more generic\n",
    "    prefix = filename[:4]\n",
    "    title = filename[5:-4]\n",
    "\n",
    "    return (prefix, title)\n",
    "\n",
    "# Generating new filenames for each chunk\n",
    "def generate_chunk_filename(filename_prefix, i):\n",
    "    return filename_prefix + \"_\" + str(i) + \".mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Name\n",
    "pkg_name = \"Mastering French Vocabulary\"\n",
    "\n",
    "# Create chapter names if available\n",
    "#pkg_chapters = {}\n",
    "pkg_chapters = { 1 : \"Personal Information\", 2 : \"The Human Body\", 3 : \"Health and Medicine\", 4 : \"Psyche, Mind, Behaviour\",\n",
    "                5 : \"Food, Clothing, Shopping\", 6 : \"Living\", 7 : \"Private Life, Social Relationships\", 8 : \"Education and Training\",\n",
    "                9 : \"Professional and Work World\", 10 : \"Leisure Activities\", 11 : \"Travel and Tourism\", 12 : \"Art, Music, Literature\",\n",
    "                13 : \"History, Religion, Philosophy\", 14 : \"State, Law, Politics\", 15 : \"Economy and Business\", 16 : \"Communication and Mass Media\",\n",
    "                17 : \"Transportation, Vehicles\", 18 : \"Nature, Environment, Ecology\", 19 : \"Time and Space\", 20 : \"Colours and Shapes\",\n",
    "                21 : \"Quantities, Measurements, Numbers\", 22 : \"General Terms\", 23 : \"Verbal Communication\", 24 : \"Language Structures\" }\n",
    "\n",
    "# Find all mp3 files\n",
    "dir = \"french_audio/\"\n",
    "save_dir = \"split_audio/\" # Place to save split tracks TODO Implement this later\n",
    "\n",
    "# Choosing files from directory\n",
    "file_numbers = [0, 1]\n",
    "\n",
    "filename_dir_list = sorted(glob.glob(dir + \"*.mp3\"))\n",
    "filename_only_list = [ f_dir.split(\"/\")[-1] for f_dir in filename_dir_list ] # Chop off directory\n",
    "chapter_list = [ int(filename.split(\".\", 1)[0]) for filename in filename_only_list] # Extract chapters from filenames\n",
    "\n",
    "# Only selecting specific files\n",
    "filenames = [filename_only_list[file_number] for file_number in file_numbers]\n",
    "chapter_names = [pkg_chapters[chapter_list[file_number]] for file_number in file_numbers]\n",
    "\n",
    "# Creating pairs of prefix and titles\n",
    "split_filenames = [split_filename(filename) for filename in filenames]\n",
    "\n",
    "tracks = [AudioSegment.from_mp3(dir + filename) for filename in filenames]\n",
    "#original_bitrates = [mediainfo(dir + filename)[\"bit_rate\"] for filename in filenames] # Redundant because later chunks inherit same bitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_filename_lists = []\n",
    "\n",
    "# Loop through every original track and split then save\n",
    "for track, (filename_prefix, _) in zip(tracks, split_filenames):\n",
    "    # Parameters empirically tuned\n",
    "    # Discard first two chunks because they're always English\n",
    "    chunks = split_on_silence(track, min_silence_len=600, silence_thresh=-40, keep_silence=300)[2:]\n",
    "\n",
    "    # Create new chunk names\n",
    "    chunk_filename_list = [generate_chunk_filename(filename_prefix, i) for i, _ in enumerate(chunks)]\n",
    "    chunk_filename_lists.append(chunk_filename_list)\n",
    "\n",
    "    # Save split up audio\n",
    "    for (chunk, chunk_name) in zip(chunks, chunk_filename_list):\n",
    "        # Only write if filename doesn't exist\n",
    "        if not os.path.isfile(chunk_name):\n",
    "            chunk.export(chunk_name, format=\"mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Model to Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd59f693f0164570b4af6d0bc554e91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14af7a02fb44f83b83d254aae45f7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs_chunk_lists = []\n",
    "\n",
    "# Costly operation\n",
    "for chunk_filename_list in chunk_filename_lists:\n",
    "    phrases_fr, phrases_en = generate_phrases(chunk_filename_list, decode_options)\n",
    "\n",
    "    # Sanitise all outputs\n",
    "    pairs = [ tuple(map(sanitise, phrase_pair)) for phrase_pair in zip(phrases_fr, phrases_en)]\n",
    "    pairs_chunk_lists.append(zip(pairs, chunk_filename_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Anki Deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'English/French with Audio'\n",
    "\n",
    "# Now have \"phrases_fr\", \"phrases_en\" and \"chunk_filename_list\", which is enough to create a deck\n",
    "random.seed(model_name)\n",
    "\n",
    "# Defining model\n",
    "# Model with audio\n",
    "model_audio = genanki.Model(\n",
    "  random.randrange(1 << 30, 1 << 31),\n",
    "  model_name,\n",
    "  fields=[\n",
    "    {'name': 'English'},\n",
    "    {'name': 'French'},\n",
    "    {'name': 'Audio'}\n",
    "  ],\n",
    "  templates=[\n",
    "    {\n",
    "      'name': 'Card',\n",
    "      'qfmt': '{{English}}<br><br>{{type:French}}',\n",
    "      'afmt': '{{FrontSide}}<hr id=\"answer\">{{French}}<br>{{Audio}}',\n",
    "    },\n",
    "    ],\n",
    "  css=\"\"\".card {\n",
    "      font-family: \"Times New Roman\", Times, serif;\n",
    "      font-size: 56pt;\n",
    "      text-align: center;\n",
    "      color: black;\n",
    "      }\n",
    "      #typeans{\n",
    "      font-family: \"Times New Roman\", Times, serif !important;\n",
    "      font-size: 40pt !important;\n",
    "      text-align: center;\n",
    "      color: black;\n",
    "      }\n",
    "      input[type=text] {\n",
    "      width: 100%;\n",
    "      text-align: center;\n",
    "      padding: 12px 0px;\n",
    "      margin: 8px 0;\n",
    "      box-sizing: border-box;\n",
    "      background-color: #eee;\n",
    "      }\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowing for multiple decks\n",
    "deck_list = []\n",
    "\n",
    "random.seed(datetime.now().timestamp())\n",
    "\n",
    "# Create Decks\n",
    "for i, ((_, filename_title), chapter_name) in enumerate(zip(split_filenames, chapter_names)):\n",
    "    # Adding \"::\" creates hierarchy within Anki\n",
    "    my_deck = genanki.Deck(\n",
    "      random.randrange(1 << 30, 1 << 31), # model_id\n",
    "      pkg_name + \"::\" + chapter_name + \"::\" + filename_title)\n",
    "\n",
    "    # Loop through words\n",
    "    pairs_chunk_list = pairs_chunk_lists[i]\n",
    "    for ((phrase_fr, phrase_en), chunk_filename) in pairs_chunk_list:\n",
    "        note = genanki.Note(model=model_audio, fields=[phrase_en, phrase_fr, \"[sound:{}]\".format(chunk_filename)])\n",
    "        my_deck.add_note(note)\n",
    "\n",
    "    # Add to deck list\n",
    "    deck_list.append(my_deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening list of chunk_filename_lists\n",
    "chunk_filename_flat = [item for sublist in chunk_filename_lists for item in sublist]\n",
    "\n",
    "# Create package\n",
    "my_package = genanki.Package(deck_list)\n",
    "my_package.media_files = chunk_filename_flat\n",
    "\n",
    "package_name = \"+\".join([filename_prefix for (filename_prefix, _) in split_filenames])\n",
    "my_package.write_to_file(package_name + \".apkg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 19:58:26) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
